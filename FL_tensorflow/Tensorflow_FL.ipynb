{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O1Yx3uj_yOu",
        "outputId": "7ffddacf-ddf5-43f0-f522-83cd1f868562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4yTxonmAGim"
      },
      "outputs": [],
      "source": [
        "main_dir = '/content/drive/MyDrive/Colab Notebooks/NTC'\n",
        "checkpoint_py = '/content/drive/MyDrive/Colab Notebooks/FL/checkpoint_manager.py'\n",
        "utils_py = '/content/drive/MyDrive/Colab Notebooks/FL/utils.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coj5n40_AJ_I",
        "outputId": "a59080af-8559-42f4-8327-9c06505e3700"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/NTC\n",
            "Accuracy.png\t\tFlower_FL  __pycache__\t     utils.py\n",
            "Accuracy_Zoom.png\tLoss.png   Result.ipynb\n",
            "checkpoint_manager.py\tmodels\t   sdn_results\n",
            "Federated_Learning_NTC\tNTC.ipynb  sdn_saved_models\n"
          ]
        }
      ],
      "source": [
        "%cd $main_dir\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjxQbx8FAUj9"
      },
      "outputs": [],
      "source": [
        "# !cp \"$checkpoint_py\" .\n",
        "# !cp \"$utils_py\" ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi-4OKhPJx90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b411e28d-fe70-4eda-d55a-8735b81a285f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkQVHE_VA-gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fd43a9-535a-490a-adb6-5b4d4da8d50a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.5/558.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.4/359.4 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for farmhashpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.15 which is incompatible.\n",
            "flax 0.6.10 requires jax>=0.4.2, but you have jax 0.3.15 which is incompatible.\n",
            "google-colab 1.0.0 requires portpicker==1.3.9, but you have portpicker 1.5.2 which is incompatible.\n",
            "orbax-checkpoint 0.2.6 requires jax>=0.4.9, but you have jax 0.3.15 which is incompatible.\n",
            "pymc 5.1.2 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboard_plugin_profile\n",
            "  Downloading tensorboard_plugin_profile-2.13.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gviz-api>=1.9.0 (from tensorboard_plugin_profile)\n",
            "  Downloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile) (67.7.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile) (1.16.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard_plugin_profile) (2.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard_plugin_profile) (2.1.3)\n",
            "Installing collected packages: gviz-api, tensorboard_plugin_profile\n",
            "Successfully installed gviz-api-1.10.0 tensorboard_plugin_profile-2.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet --upgrade tensorflow-federated\n",
        "!pip install -U tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "qHnXh2NuWJxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkvXJxAAL4Z"
      },
      "outputs": [],
      "source": [
        "# from checkpoint_manager import FileCheckpointManager\n",
        "from pathlib import Path\n",
        "import nest_asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# import tensorflow_federated as tff\n",
        "# from utils import plot_graph\n",
        "import numpy as np\n",
        "from time import time\n",
        "import os\n",
        "import logging\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuwHs3f5AuAA"
      },
      "outputs": [],
      "source": [
        "logging.disable(logging.WARNING)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "nest_asyncio.apply()\n",
        "SEED = 1337\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUACfRg9BYjY",
        "outputId": "902fa970-0034-46c7-facd-01ee60459b8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
              " LogicalDevice(name='/device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "if not gpu_devices:\n",
        "  raise ValueError('Cannot detect physical GPU device in TF')\n",
        "tf.config.list_logical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCdDCxhOBftt"
      },
      "source": [
        "### **Helper Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ABJEGSKBjA3"
      },
      "outputs": [],
      "source": [
        "def train_test_split(df, frac=0.2):\n",
        "    selected = df['flow_id'].drop_duplicates().sample(frac=frac)\n",
        "    test = df[df['flow_id'].isin(selected)]\n",
        "    train = df[~df['flow_id'].isin(selected)]\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6lLymnrBx3s"
      },
      "outputs": [],
      "source": [
        "def test_case_split(df, split):\n",
        "    # return 1 dict chia du lieu cho cac may\n",
        "    selected = df['flow_id'].drop_duplicates().sample(frac=1)\n",
        "    # print(selected.shape)\n",
        "    total_data_count = selected.shape[0]\n",
        "    data_per_set = int(np.floor(total_data_count/split))\n",
        "    DataFrameDict = {}\n",
        "    for i in range(1, split+1):\n",
        "        client_name = \"client_\" + str(i)\n",
        "        start = data_per_set * (i-1)\n",
        "        end = data_per_set * i\n",
        "\n",
        "        print(f\"Adding data from {start} to {end} for client : {client_name}\")\n",
        "        DataFrameDict[client_name] = df[df['flow_id'].isin(\n",
        "            selected[start:end])]\n",
        "    return DataFrameDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7sVVXaRCdag"
      },
      "outputs": [],
      "source": [
        "def sec_to_hours(seconds):\n",
        "    a = seconds//3600\n",
        "    b = (seconds % 3600)//60\n",
        "    c = (seconds % 3600) % 60\n",
        "    d = \"{:.0f} hours {:.0f} mins {:.0f} seconds\".format(a, b, c)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7t0NVWdCeUG"
      },
      "outputs": [],
      "source": [
        "def most_frequent(List):\n",
        "    return max(set(List), key=List.count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm5oxB8aB-Wp"
      },
      "source": [
        "Thay đổi các siêu tham số trong cell dưới <br>\n",
        "**experiment_name:** Tên bộ dữ liệu được sử dụng, <Tên dữ liệu>_<Số byte sử dụng> <br>\n",
        "**method:** Mô hình sử dụng <br>\n",
        "**client_lr, server_lr:** Learning rate của client và server, khi fine tune bắt đầu từ 1 và giảm dần xuống 3e-4 <br>\n",
        "**NUM_ROUNDS:** Số vòng lặp (Bắt đầu từ 1 và tăng dần lên 3000 nếu mô hình chưa hội tụ - 1/100/200/300/400/500/.../3000) <Br>\n",
        "**BATCH_SIZE:** Kích thước batch (Bắt đầu từ 8 và tăng dần lên 64) 8/16/32/64 <br>\n",
        "**split:** Để nguyên là 5\n",
        "<br>\n",
        "**byte_number:** (string): Cac byte cua packet, bao gom 10, 32, 64, 128, 256, 512, 1024, 1460"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxpPUTxjB-uU"
      },
      "outputs": [],
      "source": [
        "from models.CNN_2D import create_keras_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7zq8L_ACE9L"
      },
      "outputs": [],
      "source": [
        "byte_number = \"128\"\n",
        "experiment_name = \"GQUIC_small_\" + byte_number\n",
        "method = \"FL_CNN_2D\"\n",
        "\n",
        "client_lr = 0.01\n",
        "server_lr = 1\n",
        "NUM_ROUNDS = 10\n",
        "BATCH_SIZE = 64\n",
        "PACKET_NUM = 20\n",
        "split = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8GYD21DCaIO"
      },
      "outputs": [],
      "source": [
        "# this_dir = Path.cwd()\n",
        "# model_dir = this_dir / \"sdn_saved_models\" / experiment_name / method\n",
        "# output_dir = this_dir / \"sdn_results\" / experiment_name / method\n",
        "\n",
        "# if not model_dir.exists():\n",
        "#     model_dir.mkdir(parents=True)\n",
        "\n",
        "# if not output_dir.exists():\n",
        "#     output_dir.mkdir(parents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Ok7wZgChcx"
      },
      "source": [
        "### **Đọc dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCSvikBpCcB4"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/Colab Notebooks/FL/GQUIC_small/Train/GQUIC_train_' + byte_number + '.feather'\n",
        "test_dir = '/content/drive/MyDrive/Colab Notebooks/FL/GQUIC_small/Test/GQUIC_test_' + byte_number + '.feather'\n",
        "data = pd.read_feather(train_dir)\n",
        "test = pd.read_feather(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UvUkP-TI5ob",
        "outputId": "de468362-c990-4f01-9071-5d00048c9328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128 5\n"
          ]
        }
      ],
      "source": [
        "result = test.groupby('flow_id')['Label'].apply(list).to_dict()\n",
        "flow_label = []\n",
        "for flow in result:\n",
        "    flow_label.append(most_frequent(result[flow]))\n",
        "\n",
        "flow_label = np.array(flow_label)\n",
        "true_test = test.drop('flow_id', axis=1)\n",
        "NUM_FEATURE = len(true_test.columns)-1\n",
        "NUM_CLASSES = len(np.unique(true_test['Label']))\n",
        "print(NUM_FEATURE, NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2FHylRVCpkW"
      },
      "source": [
        "# **Federated Learning Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oydz5pmCqAY"
      },
      "outputs": [],
      "source": [
        "def make_tf_dataset(dataframe, batch_size=None):\n",
        "    result = dataframe.groupby('flow_id')['Label'].apply(list).to_dict()\n",
        "    y = []\n",
        "    for flow in result:\n",
        "        y.append(most_frequent(result[flow]))\n",
        "    y = np.array(y)\n",
        "    y = y.reshape(-1, 1)\n",
        "    dataframe = dataframe.drop(['Label', 'flow_id'], axis=1).to_numpy()/255\n",
        "    dataframe = dataframe.reshape(-1, PACKET_NUM, NUM_FEATURE)\n",
        "    dataframe = np.expand_dims(dataframe, -1)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dataframe, y))\n",
        "    # kieu du lieu tensorflow cho fd\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKbU4iDYDnOo",
        "outputId": "a2bbf820-fe51-46c3-d02b-ecc069e0b9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding data from 0 to 2633 for client : client_1\n",
            "Adding data from 2633 to 5266 for client : client_2\n",
            "Adding data from 5266 to 7899 for client : client_3\n",
            "Adding data from 7899 to 10532 for client : client_4\n",
            "Adding data from 10532 to 13165 for client : client_5\n"
          ]
        }
      ],
      "source": [
        "DataFrameDict = test_case_split(data, split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kOawYYrC4QO"
      },
      "outputs": [],
      "source": [
        "train_data, val_data = [], []\n",
        "for client_data in DataFrameDict.keys():\n",
        "    train_df, val_df = train_test_split(DataFrameDict[client_data], frac=0.2)\n",
        "    # TF Datasets\n",
        "    train_data.append(make_tf_dataset(train_df, batch_size=BATCH_SIZE))\n",
        "    val_data.append(make_tf_dataset(val_df, batch_size=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4PKZtsAEm6J"
      },
      "source": [
        "## **Model Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YeT568WErNE"
      },
      "outputs": [],
      "source": [
        "def input_spec():\n",
        "    return (\n",
        "        tf.TensorSpec([None, PACKET_NUM, NUM_FEATURE, 1], tf.float64),\n",
        "        tf.TensorSpec([None, 1], tf.int64)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiBYiHWvFCE3"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "    model = create_keras_model(NUM_FEATURE, NUM_CLASSES)\n",
        "\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        model,\n",
        "        input_spec=input_spec(),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmF8gQfFi_n"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMZR30B1Fl9W"
      },
      "source": [
        "Each time the **next** method is called, the server model is broadcast to each client using a broadcast function. For each client, **one** epoch of local training is performed. Each client computes the difference between the client model after training and the initial broadcast model. These model deltas are then aggregated at the server using some aggregation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ6ivV7-FkWO"
      },
      "outputs": [],
      "source": [
        "tff_train_acc = []\n",
        "tff_train_loss = []\n",
        "tff_val_acc = []\n",
        "tff_val_loss = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8xSKjLuGart"
      },
      "outputs": [],
      "source": [
        "iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    model_fn,\n",
        "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(\n",
        "        learning_rate=client_lr),\n",
        "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(\n",
        "        learning_rate=server_lr)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvKlTENOGd_4"
      },
      "outputs": [],
      "source": [
        "# Evaluate model\n",
        "evaluation_process = tff.learning.algorithms.build_fed_eval(model_fn)\n",
        "evaluation_state = evaluation_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBQG4Z-uGmgr"
      },
      "outputs": [],
      "source": [
        "# Initialize model state\n",
        "state = iterative_process.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF25RoOOG28U"
      },
      "outputs": [],
      "source": [
        "current_round = 0\n",
        "rounds_per_eval = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_td4dlrXG6Hj"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3vc8iVLGuFh",
        "outputId": "ade88ae5-2f1d-4720-b283-8b144a114e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round  1\n",
            "train_loss=11.474, train_acc=0.273, time=246.817 secs\n",
            "val_loss: 11.573 val_acc: 0.282\n",
            "round  2\n",
            "train_loss=11.528, train_acc=0.285, time=233.895 secs\n",
            "round  3\n",
            "train_loss=11.528, train_acc=0.285, time=236.100 secs\n",
            "val_loss: 11.573 val_acc: 0.282\n",
            "round  4\n",
            "train_loss=11.528, train_acc=0.285, time=235.394 secs\n"
          ]
        }
      ],
      "source": [
        "for i in range(current_round, NUM_ROUNDS):\n",
        "\n",
        "    start = time()\n",
        "    # Train\n",
        "    result = iterative_process.next(state, train_data)\n",
        "    state = result.state\n",
        "    train_metrics = result.metrics['client_work']['train']\n",
        "    duration = time() - start\n",
        "\n",
        "    # Print\n",
        "    print('round {:2d}\\ntrain_loss={l:.3f}, train_acc={ac:.3f}, time={d:.3f} secs'.format(\n",
        "        i+1, l=train_metrics['loss'], ac=train_metrics['sparse_categorical_accuracy'], d=duration))\n",
        "\n",
        "    # Validation\n",
        "    if i % rounds_per_eval == 0 or i == NUM_ROUNDS - 1:\n",
        "      evaluation_state = evaluation_process.set_model_weights(evaluation_state,result.state.global_model_weights)\n",
        "      evaluation_output = evaluation_process.next(evaluation_state, val_data)\n",
        "      val_metrics = evaluation_output.metrics['client_work']['eval']['current_round_metrics']\n",
        "      print('val_loss: {:.3f} val_acc: {:.3f}'.format(\n",
        "        val_metrics['loss'], val_metrics['sparse_categorical_accuracy']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}